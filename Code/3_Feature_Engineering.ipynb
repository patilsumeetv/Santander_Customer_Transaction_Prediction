{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import lightgbm as lgbm\n",
    "from process_functions import train_test_loader\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = (140000, 200)\n",
      "Testing Size = (60000, 200)\n",
      "No. of positive in training = 13964\n",
      "No. of positive in testing = 6134\n"
     ]
    }
   ],
   "source": [
    "train_features, train_target, test_features, test_target = train_test_loader('../Data/Feature_Engineering')\n",
    "\n",
    "print(\"Training Size = {}\".format(train_features.shape))\n",
    "print(\"Testing Size = {}\".format(test_features.shape))\n",
    "\n",
    "print(\"No. of positive in training = {}\".format(train_target.sum()[0]))\n",
    "print(\"No. of positive in testing = {}\".format(test_target.sum()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing LightGBM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lgbm = lgbm.Dataset(data=train_features, label=train_target)\n",
    "test_lgbm = train_lgbm.create_valid(data=test_features, label=test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10000 rounds.\n",
      "[10000]\ttraining's auc: 0.909846\tvalid_1's auc: 0.895208\n",
      "[20000]\ttraining's auc: 0.921065\tvalid_1's auc: 0.899274\n"
     ]
    }
   ],
   "source": [
    "lgbm_parameter = {\n",
    "    'num_leaves' : 3,\n",
    "    'min_data_in_leaf' : 20,\n",
    "    'max_depth' : 16,\n",
    "    'bagging_fraction' : 0.4,\n",
    "    'bagging_freq' : 5,\n",
    "    'feature_fraction' : 0.1,\n",
    "    'learning_rate' : 0.01,\n",
    "    'boosting' : 'gbdt',\n",
    "    'random_state' : 0,\n",
    "    'num_boost_round' : 100000,\n",
    "    'objective' : 'binary',\n",
    "    'num_threads' : 3,\n",
    "    'boosting_from_average' : True,\n",
    "    'metric' : 'auc',\n",
    "}\n",
    "\n",
    "bst = lgbm.train(lgbm_parameter, train_set=train_lgbm, valid_sets=[train_lgbm, test_lgbm], \\\n",
    "                 verbose_eval=10000, early_stopping_rounds=10000)\n",
    "\n",
    "# cv_model = lgbm.cv(lgbm_parameter, train_set=cv_data, num_boost_round=100, nfold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_imp = bst.feature_importance(importance_type='gain')\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(200), np.sort(feature_imp)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.sort(feature_imp)[::-1][0:5]:\n",
    "    print(i)\n",
    "    print(np.where(feature_imp==i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft, train_tar, test_ft, test_tar = train_features, train_target, test_features, test_target\n",
    "\n",
    "print(\"Training Features = {}\".format(train_ft.shape))\n",
    "print(\"Testing Features = {}\".format(test_ft.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding more features in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft['var_200'] = np.square(train_ft.var_81)/np.sqrt(train_ft.var_81)\n",
    "train_ft['var_201'] = np.square(train_ft.var_139)\n",
    "train_ft['var_202'] = np.square(train_ft.var_12)/np.sqrt(train_ft.var_12)\n",
    "train_ft['var_203'] = np.square(train_ft.var_110)/np.sqrt(train_ft.var_110)\n",
    "train_ft['var_204'] = np.square(train_ft.var_6)/np.sqrt(train_ft.var_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding more features in testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ft['var_200'] = np.square(test_ft.var_81)/np.sqrt(test_ft.var_81)\n",
    "test_ft['var_201'] = np.square(test_ft.var_139)\n",
    "test_ft['var_202'] = np.square(test_ft.var_12)/np.sqrt(test_ft.var_12)\n",
    "test_ft['var_203'] = np.square(test_ft.var_110)/np.sqrt(test_ft.var_110)\n",
    "test_ft['var_204'] = np.square(test_ft.var_6)/np.sqrt(test_ft.var_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Training Features = {}\".format(train_ft.shape))\n",
    "print(\"Testing Features = {}\".format(test_ft.shape))\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Training Target = {}\".format(train_tar.shape))\n",
    "print(\"Testing Target = {}\".format(test_tar.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing LightGBM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = lgbm.Dataset(data=train_ft, label=train_tar)\n",
    "feature_test = train_lgbm.create_valid(data=test_ft, label=test_tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgbm_parameter = {\n",
    "    'num_leaves' : 3,\n",
    "    'min_data_in_leaf' : 20,\n",
    "    'max_depth' : 16,\n",
    "    'bagging_fraction' : 0.4,\n",
    "    'bagging_freq' : 5,\n",
    "    'feature_fraction' : 0.1,\n",
    "    'learning_rate' : 0.01,\n",
    "    'boosting' : 'gbdt',\n",
    "    'random_state' : 0,\n",
    "    'num_boost_round' : 100000,\n",
    "    'objective' : 'binary',\n",
    "    'num_threads' : 3,\n",
    "    'boost_from_average' : True,\n",
    "    'metric' : 'auc',\n",
    "}\n",
    "\n",
    "ft_bst = lgbm.train(lgbm_parameter, train_set=feature_train, valid_sets=[feature_train, feature_test], \\\n",
    "                    verbose_eval=10000, early_stopping_rounds=10000)\n",
    "\n",
    "# cv_model = lgbm.cv(lgbm_parameter, train_set=cv_data, num_boost_round=100, nfold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
